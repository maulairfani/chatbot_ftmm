{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHATBOT FTMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"knowledges\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"database\")\n",
    "collection_ftmm = client.get_or_create_collection(name=\"ftmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [docs[i].metadata for i in range(len(docs))]\n",
    "documents = [docs[i].page_content for i in range(len(docs))]\n",
    "ids = [f\"doc{i}\" for i in range(len(docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = OpenAIEmbeddings()\n",
    "embeddings = embed.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: doc0\n",
      "Add of existing embedding ID: doc1\n",
      "Add of existing embedding ID: doc2\n",
      "Add of existing embedding ID: doc3\n",
      "Add of existing embedding ID: doc4\n",
      "Add of existing embedding ID: doc5\n",
      "Add of existing embedding ID: doc6\n",
      "Insert of existing embedding ID: doc0\n",
      "Insert of existing embedding ID: doc1\n",
      "Insert of existing embedding ID: doc2\n",
      "Insert of existing embedding ID: doc3\n",
      "Insert of existing embedding ID: doc4\n",
      "Insert of existing embedding ID: doc5\n",
      "Insert of existing embedding ID: doc6\n"
     ]
    }
   ],
   "source": [
    "status = collection_ftmm.add(\n",
    "    ids=ids,\n",
    "    documents=documents,\n",
    "    embeddings=embeddings,\n",
    "    metadatas=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch = Chroma(persist_directory=\"database\", embedding_function=embed, collection_name=\"ftmm\")\n",
    "docsearch._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "# Template prompt\n",
    "template = \"\"\"Jawablah pertanyaan di bawah ini berdasarkan konteks yang diberikan! \\\n",
    "Jika dalam pertanyaan merujuk ke histori chat sebelumnya, maka gunakan konteks dari pertanyaan \\\n",
    "sebelumnya untuk menjawab!\n",
    "Konteks:\n",
    "{context}\n",
    "\n",
    "Pertanyaan:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "template_system = \"\"\"Namamu adalah Iris, sebuah chatbot Fakultas Teknologi Maju dan \\\n",
    "Multidisiplin (FTMM), Universitas Airlangga. Kamu siap menjawab pertanyaan apapun \\\n",
    "seputar FTMM. Kamu menjawab setiap pertanyaan dengan ceria, sopan, dan asik!\n",
    "\"\"\"\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(template_system),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Memory\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Fakultas Teknologi Maju dan Multidisiplin (FTMM) didirikan pada bulan November 2019 dengan nama awal \"Sekolah Teknologi Maju dan Multidisiplin\". FTMM hadir sebagai pelengkap dari tiga pilar utama Universitas Airlangga yaitu ilmu sosial, ilmu kehidupan, dan ilmu kesehatan, dengan menambahkan pilar baru di bidang keteknikan.\\n\\nFTMM memiliki lima program studi S1 yang terdiri dari Teknik Robotika dan Kecerdasan Buatan, Teknologi Sains Data, Rekayasa Nanoteknologi, Teknik Industri, dan Teknik Elektro. Pada tahun pertama, jumlah mahasiswa FTMM sekitar 400 orang.\\n\\nSebagai fakultas baru, FT')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"ceritakan sejarah FTMM!\"\n",
    "contexts = docsearch.similarity_search(question, k=3)\n",
    "response = chain.invoke({\"context\": contexts, \"question\": question, \"chat_history\": memory.buffer_as_messages})\n",
    "\n",
    "# Add response to memory\n",
    "memory.save_context({\"input\": template.format(context=contexts, question=question)}, \n",
    "                    {\"output\": response.content})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177\n"
     ]
    }
   ],
   "source": [
    "folder = \"Website FTMM\"\n",
    "for i in range(len(os.listdir(folder))):\n",
    "    file_path = os.path.join(folder, os.listdir(folder)[i])\n",
    "    with open(file_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    tokens = encoder.encode(content)\n",
    "    print(len(tokens))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = docsearch.similarity_search(\"apa itu arta\", k=3)\n",
    "temp = f\"{contexts}\"\n",
    "\n",
    "tokens = encoder.encode(temp)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = encoder.encode(f\"{memory.buffer_as_messages}\")\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = docsearch.similarity_search(\"jadi apa itu arta?\", k=3)\n",
    "temp = f\"{contexts}\"\n",
    "\n",
    "tokens = encoder.encode(temp)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n"
     ]
    }
   ],
   "source": [
    "saved_contexts = list()\n",
    "\n",
    "contexts = [c for c in docsearch.similarity_search(\"apa itu arta?\", k=3) if c not in saved_contexts]\n",
    "print(len(contexts), len(saved_contexts))\n",
    "saved_contexts = contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n"
     ]
    }
   ],
   "source": [
    "contexts = [c for c in docsearch.similarity_search(\"berarti apa tujuan arta?\", k=3) if c not in saved_contexts]\n",
    "print(len(contexts), len(saved_contexts))\n",
    "# saved_contexts = contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_contexts.extend(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2323"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = encoder.encode(f\"{saved_contexts}\")\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = docsearch.similarity_search(\"berarti apa tujuan arta?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3993"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = prompt.format(context=contexts, question=\"berarti apa tujuan arta?\", chat_history=memory.buffer_as_messages)\n",
    "tokens = encoder.encode(temp)\n",
    "len(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
