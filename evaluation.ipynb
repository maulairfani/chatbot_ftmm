{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever Evaluation\n",
    "\n",
    "**Metrics**: Recall, Precision\n",
    "\n",
    "**Embeddings** methods: OpenAI Ada, Google Embedding-001, MPNet-Multilingual\n",
    "\n",
    "**Retriever type**: Similarity Search, MMR Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=st.secrets[\"google_api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=hf_ftmm), Collection(name=gemini_ftmm), Collection(name=ftmm)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memastikan vector database sudah sama\n",
    "client = chromadb.PersistentClient(\"knowledge_database\")\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "embed_openai = OpenAIEmbeddings(openai_api_key=st.secrets[\"openai_key\"])\n",
    "docsearch_openai =  Chroma(persist_directory=\"knowledge_database\", collection_name=\"ftmm\", embedding_function=embed_openai)\n",
    "\n",
    "# Huggingface\n",
    "embed_hf = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "docsearch_hf = Chroma(persist_directory=\"knowledge_database\", collection_name=\"hf_ftmm\", embedding_function=embed_hf)\n",
    "\n",
    "# Google\n",
    "def embed_fn(text):\n",
    "    return genai.embed_content(model=\"models/embedding-001\", content=text, task_type=\"retrieval_document\")[\"embedding\"]\n",
    "docsearch_google = Chroma(persist_directory=\"knowledge_database\", collection_name=\"gemini_ftmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks in the collection\n",
      "OpenAI: 227\n",
      "Huggingface: 227\n",
      "Google: 227\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Chunks in the collection\")\n",
    "print(f\"OpenAI: {docsearch_openai._collection.count()}\")\n",
    "print(f\"Huggingface: {docsearch_hf._collection.count()}\")\n",
    "print(f\"Google: {docsearch_google._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_docs</th>\n",
       "      <th>title_1</th>\n",
       "      <th>title_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pengenalan FTMM</td>\n",
       "      <td>FTMM adalah</td>\n",
       "      <td>[92, 75]</td>\n",
       "      <td>Sejarah FTMM.txt</td>\n",
       "      <td>Prestasi Mahasiswa.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lokasi FTMM</td>\n",
       "      <td>Halo FTMM ada dimana?</td>\n",
       "      <td>[92, 32]</td>\n",
       "      <td>Sejarah FTMM.txt</td>\n",
       "      <td>FTMM Overview.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Informasi Kontak</td>\n",
       "      <td>Apakah FTMM mempunyai akun media sosial?</td>\n",
       "      <td>[81]</td>\n",
       "      <td>QnA.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sejarah FTMM</td>\n",
       "      <td>Berapa jumlah mahasiswa FTMM?</td>\n",
       "      <td>[92]</td>\n",
       "      <td>Sejarah FTMM.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Prodi FTMM</td>\n",
       "      <td>Apakah ada jurusan yang hanya ada satu di Indo...</td>\n",
       "      <td>[93, 32]</td>\n",
       "      <td>Selayang Pandang FTMM.txt</td>\n",
       "      <td>FTMM Overview.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               tag                                              query  \\\n",
       "0   0   Pengenalan FTMM                                        FTMM adalah   \n",
       "1   1       Lokasi FTMM                              Halo FTMM ada dimana?   \n",
       "2   2  Informasi Kontak           Apakah FTMM mempunyai akun media sosial?   \n",
       "3   3      Sejarah FTMM                      Berapa jumlah mahasiswa FTMM?   \n",
       "4   4        Prodi FTMM  Apakah ada jurusan yang hanya ada satu di Indo...   \n",
       "\n",
       "  relevant_docs                    title_1                 title_2  \n",
       "0      [92, 75]           Sejarah FTMM.txt  Prestasi Mahasiswa.txt  \n",
       "1      [92, 32]           Sejarah FTMM.txt       FTMM Overview.txt  \n",
       "2          [81]                    QnA.txt                     NaN  \n",
       "3          [92]           Sejarah FTMM.txt                     NaN  \n",
       "4      [93, 32]  Selayang Pandang FTMM.txt       FTMM Overview.txt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Test untuk Retrieval\n",
    "corpus = pd.read_csv(\"corpus.csv\")\n",
    "retrieval_data = pd.read_csv(\"relevant_docs.csv\")\n",
    "retrieval_data['relevant_docs'] = retrieval_data['relevant_docs'].apply(lambda x: ast.literal_eval(x))\n",
    "retrieval_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retriever:** Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:30<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# OpenAI\n",
    "retrieved_docs_openai = list()\n",
    "for i in tqdm(range(len(retrieval_data))):\n",
    "    q = retrieval_data[\"query\"].iloc[i]\n",
    "    retrieved_docs = docsearch_openai.similarity_search(q, k=2)\n",
    "    docs_title = [d.metadata[\"source\"][11:] for d in retrieved_docs]\n",
    "    docs_id = [corpus[corpus[\"file_name\"] == docs_title[i]][\"id\"].values[0] for i in range(len(docs_title))]\n",
    "    retrieved_docs_openai.append(docs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:04<00:00, 14.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace\n",
    "retrieved_docs_hf = list()\n",
    "for i in tqdm(range(len(retrieval_data))):\n",
    "    q = retrieval_data[\"query\"].iloc[i]\n",
    "    retrieved_docs = docsearch_hf.similarity_search(q, k=2)\n",
    "    docs_title = [d.metadata[\"source\"][11:] for d in retrieved_docs]\n",
    "    docs_id = [corpus[corpus[\"file_name\"] == docs_title[i]][\"id\"].values[0] for i in range(len(docs_title))]\n",
    "    retrieved_docs_hf.append(docs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:41<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Google\n",
    "retrieved_docs_google = list()\n",
    "for i in tqdm(range(len(retrieval_data))):\n",
    "    q = retrieval_data[\"query\"].iloc[i]\n",
    "    embedding = embed_fn(q)\n",
    "    retrieved_docs = docsearch_google.similarity_search_by_vector(embedding, k=2)\n",
    "    docs_title = [d.metadata[\"source\"][11:] for d in retrieved_docs]\n",
    "    docs_id = [corpus[corpus[\"file_name\"] == docs_title[i]][\"id\"].values[0] for i in range(len(docs_title))]\n",
    "    retrieved_docs_google.append(docs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_data[\"ss_openai\"] = retrieved_docs_openai\n",
    "retrieval_data[\"ss_hf\"] = retrieved_docs_hf\n",
    "retrieval_data[\"ss_google\"] = retrieved_docs_google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retriever:** MMR Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:28<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# OpenAI\n",
    "retrieved_docs_openai = list()\n",
    "for i in tqdm(range(len(retrieval_data))):\n",
    "    q = retrieval_data[\"query\"].iloc[i]\n",
    "    retrieved_docs = docsearch_openai.max_marginal_relevance_search(q, k=2)\n",
    "    docs_title = [d.metadata[\"source\"][11:] for d in retrieved_docs]\n",
    "    docs_id = [corpus[corpus[\"file_name\"] == docs_title[i]][\"id\"].values[0] for i in range(len(docs_title))]\n",
    "    retrieved_docs_openai.append(docs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:04<00:00, 15.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace\n",
    "retrieved_docs_hf = list()\n",
    "for i in tqdm(range(len(retrieval_data))):\n",
    "    q = retrieval_data[\"query\"].iloc[i]\n",
    "    retrieved_docs = docsearch_hf.max_marginal_relevance_search(q, k=2)\n",
    "    docs_title = [d.metadata[\"source\"][11:] for d in retrieved_docs]\n",
    "    docs_id = [corpus[corpus[\"file_name\"] == docs_title[i]][\"id\"].values[0] for i in range(len(docs_title))]\n",
    "    retrieved_docs_hf.append(docs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:26<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Google\n",
    "retrieved_docs_google = list()\n",
    "for i in tqdm(range(len(retrieval_data))):\n",
    "    q = retrieval_data[\"query\"].iloc[i]\n",
    "    embedding = embed_fn(q)\n",
    "    retrieved_docs = docsearch_google.max_marginal_relevance_search_by_vector(embedding, k=2)\n",
    "    docs_title = [d.metadata[\"source\"][11:] for d in retrieved_docs]\n",
    "    docs_id = [corpus[corpus[\"file_name\"] == docs_title[i]][\"id\"].values[0] for i in range(len(docs_title))]\n",
    "    retrieved_docs_google.append(docs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_data[\"mmr_openai\"] = retrieved_docs_openai\n",
    "retrieval_data[\"mmr_hf\"] = retrieved_docs_hf\n",
    "retrieval_data[\"mmr_google\"] = retrieved_docs_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_data.to_csv(\"result_retrieval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(true_values, predicted_values):\n",
    "    true_positives = set(true_values) & set(predicted_values)\n",
    "    false_positives = set(predicted_values) - set(true_values)\n",
    "    false_negatives = set(true_values) - set(predicted_values)\n",
    "\n",
    "    recall = len(true_positives) / (len(true_positives) + len(false_negatives)) if (len(true_positives) + len(false_negatives)) > 0 else 0\n",
    "    precision = len(true_positives) / (len(true_positives) + len(false_positives)) if (len(true_positives) + len(false_positives)) > 0 else 0\n",
    "\n",
    "    return recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"ss_openai\", \"ss_hf\", \"ss_google\", \"mmr_openai\", \"mmr_hf\", \"mmr_google\"]\n",
    "\n",
    "result = dict()\n",
    "for e in experiments:\n",
    "    recall_list = list()\n",
    "    precision_list = list()\n",
    "    for i in range(len(retrieval_data)):\n",
    "        true, pred = retrieval_data[[\"relevant_docs\", e]].iloc[i].values\n",
    "        r, p = evaluation(true, pred)\n",
    "        recall_list.append(r)\n",
    "        precision_list.append(p)\n",
    "        \n",
    "    avg_recall = sum(recall_list) / len(recall_list)\n",
    "    avg_precision = sum(precision_list) / len(precision_list)\n",
    "\n",
    "    result[e] = {\"recall\": round(avg_recall, 4) * 100, \"precision\": round(avg_precision, 4) * 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv(\"metrics_retrieval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ss_openai</th>\n",
       "      <th>ss_hf</th>\n",
       "      <th>ss_google</th>\n",
       "      <th>mmr_openai</th>\n",
       "      <th>mmr_hf</th>\n",
       "      <th>mmr_google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>86.07</td>\n",
       "      <td>53.28</td>\n",
       "      <td>22.95</td>\n",
       "      <td>59.02</td>\n",
       "      <td>47.54</td>\n",
       "      <td>22.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>77.05</td>\n",
       "      <td>45.90</td>\n",
       "      <td>19.67</td>\n",
       "      <td>48.36</td>\n",
       "      <td>39.34</td>\n",
       "      <td>18.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ss_openai  ss_hf  ss_google  mmr_openai  mmr_hf  mmr_google\n",
       "recall         86.07  53.28      22.95       59.02   47.54       22.95\n",
       "precision      77.05  45.90      19.67       48.36   39.34       18.85"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the Quality of Generated Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intentsFTMM.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)[\"intents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FTMM adalah</td>\n",
       "      <td>Fakultas Teknologi Maju dan Multidisiplin (FTM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo FTMM itu apa?</td>\n",
       "      <td>Fakultas Teknologi Maju dan Multidisiplin (FTM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kapan FTMM didirikan?</td>\n",
       "      <td>Fakultas Teknologi Maju dan Multidisiplin (FTM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ada berapa program studi di FTMM?</td>\n",
       "      <td>Fakultas Teknologi Maju dan Multidisiplin (FTM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Apa saja program studi yang ada di FTMM?</td>\n",
       "      <td>Fakultas Teknologi Maju dan Multidisiplin (FTM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                  question  \\\n",
       "0      0                               FTMM adalah   \n",
       "1      1                        Halo FTMM itu apa?   \n",
       "2      2                     Kapan FTMM didirikan?   \n",
       "3      3         Ada berapa program studi di FTMM?   \n",
       "4      4  Apa saja program studi yang ada di FTMM?   \n",
       "\n",
       "                                              answer  \n",
       "0  Fakultas Teknologi Maju dan Multidisiplin (FTM...  \n",
       "1  Fakultas Teknologi Maju dan Multidisiplin (FTM...  \n",
       "2  Fakultas Teknologi Maju dan Multidisiplin (FTM...  \n",
       "3  Fakultas Teknologi Maju dan Multidisiplin (FTM...  \n",
       "4  Fakultas Teknologi Maju dan Multidisiplin (FTM...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = list()\n",
    "answer = list()\n",
    "for i in range(1, len(data)):\n",
    "    sample = data[i]\n",
    "    for j in range(len(sample[\"patterns\"])):\n",
    "        question.append(sample[\"patterns\"][j])\n",
    "        answer.append(sample[\"responses\"][0])\n",
    "QA_pair = pd.DataFrame({\n",
    "    \"question\": question,\n",
    "    \"answer\": answer\n",
    "})\n",
    "QA_pair = QA_pair.reset_index()\n",
    "QA_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maula\\AppData\\Local\\Temp\\ipykernel_32488\\1141484958.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n",
    "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(prediction, reference):\n",
    "    bleu_metric.add(prediction=prediction, reference=reference)\n",
    "    results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "    results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "    return results\n",
    "\n",
    "def compute_rouge(prediction, reference):\n",
    "    rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "    rouge_metric.add(prediction=prediction, reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    results = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt and Memory\n",
    "# Template prompt\n",
    "template = \"\"\"Jawablah pertanyaan di bawah ini berdasarkan konteks yang diberikan! \\\n",
    "Jika dalam pertanyaan merujuk ke histori chat sebelumnya, maka gunakan konteks dari pertanyaan \\\n",
    "sebelumnya untuk menjawab!\n",
    "Konteks:\n",
    "{context}\n",
    "\n",
    "Pertanyaan:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "template_system = \"\"\"Namamu adalah FTMMQA, sebuah chatbot Fakultas Teknologi Maju dan \\\n",
    "Multidisiplin (FTMM), Universitas Airlangga. Kamu siap menjawab pertanyaan apapun \\\n",
    "seputar FTMM. Kamu menjawab setiap pertanyaan dengan ceria, sopan, dan asik!\n",
    "\"\"\"\n",
    "\n",
    "# Prompt\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(template_system),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Memory\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = OpenAIEmbeddings(openai_api_key=st.secrets[\"openai_key\"])\n",
    "docsearch = Chroma(persist_directory=\"knowledge_database\", collection_name=\"ftmm\", embedding_function=embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatGoogleGenerativeAI(model=\"gemini-pro\", \n",
    "                                    temperature=0, \n",
    "                                    google_api_key=st.secrets[\"google_api_key\"],\n",
    "                                    convert_system_message_to_human=True)\n",
    "chain = prompt_template | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gemini = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 36/90 [02:55<03:51,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: index: 0\n",
      "finish_reason: RECITATION\n",
      "\n",
      "Error: index: 0\n",
      "finish_reason: RECITATION\n",
      "\n",
      "Error: index: 0\n",
      "finish_reason: RECITATION\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 37/90 [03:39<14:14, 16.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed after 3 retries. Moving to the next item.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 69/90 [06:08<01:39,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: index: 0\n",
      "finish_reason: RECITATION\n",
      "\n",
      "Error: index: 0\n",
      "finish_reason: RECITATION\n",
      "\n",
      "Error: index: 0\n",
      "finish_reason: RECITATION\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 70/90 [06:56<05:49, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed after 3 retries. Moving to the next item.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [08:55<00:00,  5.95s/it]\n"
     ]
    }
   ],
   "source": [
    "max_retries = 3\n",
    "\n",
    "for i in tqdm(range(len(QA_pair))):\n",
    "    retries = 0\n",
    "    success = False\n",
    "\n",
    "    while retries < max_retries and not success:\n",
    "        try:\n",
    "            q = QA_pair.iloc[i][\"question\"]\n",
    "            contexts = docsearch.similarity_search(q, k=2)\n",
    "            start = time.time()\n",
    "            r = chain.invoke({\"question\": q, \"context\":contexts, \"chat_history\":[]})\n",
    "            result_gemini[str(i)] = {\n",
    "                \"response\": r,\n",
    "                \"time\": time.time() - start\n",
    "            }\n",
    "            time.sleep(1)\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(10)\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Failed after {max_retries} retries. Moving to the next item.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "keys = [int(k) for k in result_gemini.keys()]\n",
    "for i in range(len(QA_pair)):\n",
    "    if i not in keys:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maula\\AppData\\Local\\Temp\\ipykernel_32488\\1899380625.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_result_gemini_NA = pd.concat([df_result_gemini, pd.DataFrame({\n",
      "100%|██████████| 90/90 [00:12<00:00,  7.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# result to dataframe\n",
    "df_result_gemini = pd.DataFrame({\n",
    "    \"index\": [int(i) for i in result_gemini.keys()],\n",
    "    \"response\": [result_gemini[k]['response'].content for k in result_gemini.keys()],\n",
    "    \"running_time\": [result_gemini[k]['time'] for k in result_gemini.keys()]\n",
    "})\n",
    "\n",
    "# handling errors\n",
    "df_result_gemini_NA = pd.concat([df_result_gemini, pd.DataFrame({\n",
    "    \"index\" : [36, 69],\n",
    "    \"response\" : [pd.NA, pd.NA],\n",
    "    \"running_time\" : [pd.NA, pd.NA]\n",
    "})]).reset_index(drop=True)\n",
    "\n",
    "# fix df\n",
    "RESULT_GEMINI = QA_pair.copy()\n",
    "RESULT_GEMINI[\"response_gemini\"] = df_result_gemini_NA[\"response\"].copy()\n",
    "RESULT_GEMINI[\"running_time_gemini\"] = df_result_gemini_NA[\"running_time\"].copy()\n",
    "\n",
    "# compute metrics and update fix df\n",
    "BLEU_GEMINI = list()\n",
    "ROUGE_GEMINI = list()\n",
    "for i in tqdm(range(len(QA_pair))):\n",
    "    p = RESULT_GEMINI[\"response_gemini\"].iloc[i]\n",
    "    r = RESULT_GEMINI[\"answer\"].iloc[i]\n",
    "    BLEU_GEMINI.append(compute_bleu(p, [r]))\n",
    "    ROUGE_GEMINI.append(compute_rouge(p, [r]))\n",
    "\n",
    "# fixx df\n",
    "RESULT_GEMINI = pd.concat([RESULT_GEMINI, pd.DataFrame(BLEU_GEMINI), pd.DataFrame(ROUGE_GEMINI)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPENAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(temperature=0, \n",
    "                        openai_api_key=st.secrets[\"openai_key\"])\n",
    "chain = prompt_template | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_openai = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [12:25<00:00,  8.28s/it]\n"
     ]
    }
   ],
   "source": [
    "max_retries = 3\n",
    "\n",
    "for i in tqdm(range(len(QA_pair))):\n",
    "    retries = 0\n",
    "    success = False\n",
    "\n",
    "    while retries < max_retries and not success:\n",
    "        try:\n",
    "            q = QA_pair.iloc[i][\"question\"]\n",
    "            contexts = docsearch.similarity_search(q, k=2)\n",
    "            start = time.time()\n",
    "            r = chain.invoke({\"question\": q, \"context\":contexts, \"chat_history\":[]})\n",
    "            result_openai[str(i)] = {\n",
    "                \"response\": r,\n",
    "                \"time\": time.time() - start\n",
    "            }\n",
    "            time.sleep(1)\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(10)\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Failed after {max_retries} retries. Moving to the next item.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maula\\AppData\\Local\\Temp\\ipykernel_32488\\3577230485.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_result_openai_NA = pd.concat([df_result_openai, pd.DataFrame({\n",
      "100%|██████████| 90/90 [00:12<00:00,  7.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# result to dataframe\n",
    "df_result_openai = pd.DataFrame({\n",
    "    \"index\": [int(i) for i in result_openai.keys()],\n",
    "    \"response\": [result_openai[k]['response'].content for k in result_openai.keys()],\n",
    "    \"running_time\": [result_openai[k]['time'] for k in result_openai.keys()]\n",
    "})\n",
    "\n",
    "# handling errors\n",
    "df_result_openai_NA = pd.concat([df_result_openai, pd.DataFrame({\n",
    "    \"index\" : [i for i in range(10, len(QA_pair))],\n",
    "    \"response\" : [pd.NA for i in range(10, len(QA_pair))],\n",
    "    \"running_time\" : [pd.NA for i in range(10, len(QA_pair))]\n",
    "})]).reset_index(drop=True)\n",
    "\n",
    "# fix df\n",
    "RESULT_OPENAI = QA_pair.copy()\n",
    "RESULT_OPENAI[\"response_openai\"] = df_result_openai_NA[\"response\"].copy()\n",
    "RESULT_OPENAI[\"running_time_openai\"] = df_result_openai_NA[\"running_time\"].copy()\n",
    "\n",
    "# compute metrics and update fix df\n",
    "BLEU_OPENAI = list()\n",
    "ROUGE_OPENAI = list()\n",
    "for i in tqdm(range(len(QA_pair))):\n",
    "    p = RESULT_OPENAI[\"response_openai\"].iloc[i]\n",
    "    r = RESULT_OPENAI[\"answer\"].iloc[i]\n",
    "    BLEU_OPENAI.append(compute_bleu(p, [r]))\n",
    "    ROUGE_OPENAI.append(compute_rouge(p, [r]))\n",
    "\n",
    "# fixx df\n",
    "RESULT_OPENAI = pd.concat([RESULT_OPENAI, pd.DataFrame(BLEU_OPENAI), pd.DataFrame(ROUGE_OPENAI)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_GEMINI.to_csv(\"result_gemini.csv\", index=False)\n",
    "RESULT_OPENAI.to_csv(\"result_openai.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_retrieval = pd.read_csv(\"result_retrieval.csv\")\n",
    "\n",
    "columns_list = [\"relevant_docs\", \"ss_openai\", \"ss_hf\", \"ss_google\", \"mmr_openai\", \"mmr_hf\", \"mmr_google\"]\n",
    "for c in columns_list:\n",
    "    result_retrieval[c] = result_retrieval[c].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = result_retrieval[\"relevant_docs\"]\n",
    "\n",
    "label_k1 = label.apply(lambda x: [x[0]])\n",
    "ss_openai_k1 = result_retrieval[\"ss_openai\"].apply(lambda x: [x[0]])\n",
    "ss_google_k1 = result_retrieval[\"ss_google\"].apply(lambda x: [x[0]])\n",
    "ss_hf_k1 = result_retrieval[\"ss_hf\"].apply(lambda x: [x[0]])\n",
    "mmr_openai_k1 = result_retrieval[\"mmr_openai\"].apply(lambda x: [x[0]])\n",
    "mmr_google_k1 = result_retrieval[\"mmr_google\"].apply(lambda x: [x[0]])\n",
    "mmr_hf_k1 = result_retrieval[\"mmr_hf\"].apply(lambda x: [x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [ss_openai_k1, ss_google_k1, ss_hf_k1, mmr_openai_k1, mmr_google_k1, mmr_hf_k1]\n",
    "experiments_name = [\"ss_openai_k1\", \"ss_google_k1\", \"ss_hf_k1\", \"mmr_openai_k1\", \"mmr_google_k1\", \"mmr_hf_k1\"]\n",
    "\n",
    "result = dict()\n",
    "for e, name in zip(experiments, experiments_name):\n",
    "    recall_list = list()\n",
    "    precision_list = list()\n",
    "    for i in range(len(result_retrieval)):\n",
    "        true, pred = label_k1[i], e[i]\n",
    "        r, p = evaluation(true, pred)\n",
    "        recall_list.append(r)\n",
    "        precision_list.append(p)\n",
    "        \n",
    "    avg_recall = sum(recall_list) / len(recall_list)\n",
    "    avg_precision = sum(precision_list) / len(precision_list)\n",
    "\n",
    "    result[name] = {\"recall\": round(avg_recall, 4) * 100, \"precision\": round(avg_precision, 4) * 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ss_openai_k1</th>\n",
       "      <th>ss_google_k1</th>\n",
       "      <th>ss_hf_k1</th>\n",
       "      <th>mmr_openai_k1</th>\n",
       "      <th>mmr_google_k1</th>\n",
       "      <th>mmr_hf_k1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>85.25</td>\n",
       "      <td>6.56</td>\n",
       "      <td>65.57</td>\n",
       "      <td>85.25</td>\n",
       "      <td>6.56</td>\n",
       "      <td>65.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>85.25</td>\n",
       "      <td>6.56</td>\n",
       "      <td>65.57</td>\n",
       "      <td>85.25</td>\n",
       "      <td>6.56</td>\n",
       "      <td>65.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ss_openai_k1  ss_google_k1  ss_hf_k1  mmr_openai_k1  mmr_google_k1  \\\n",
       "recall            85.25          6.56     65.57          85.25           6.56   \n",
       "precision         85.25          6.56     65.57          85.25           6.56   \n",
       "\n",
       "           mmr_hf_k1  \n",
       "recall         65.57  \n",
       "precision      65.57  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_ftmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
